diff --git a/esc-50/setup.py b/esc-50/setup.py
index 6f4495c..b5e161d 100644
--- a/esc-50/setup.py
+++ b/esc-50/setup.py
@@ -2,7 +2,7 @@ from fastai.vision.all import *
 from fastaudio.core.all import *
 
 # ensure the dataset is downloaded to the local machine
-path = untar_data(URLs.ESC50)
+path = untar_data(URLs.DOGS)
 
 # ensure all the pretrained weights are downloaded
 models = [
diff --git a/esc-50/train.py b/esc-50/train.py
index 8f5205e..fe1d8c6 100644
--- a/esc-50/train.py
+++ b/esc-50/train.py
@@ -1,3 +1,5 @@
+import wandb
+
 from utils import *
 assert torch.cuda.is_available()
 
@@ -11,7 +13,7 @@ run_config = dict(
     f_max=20000,
 
     # model
-    arch='resnet18',
+    arch='resnet34',
 
     # training
     learning_rate=1e-2,
@@ -25,6 +27,8 @@ run_config = dict(
     fold=1,
 )
 
+wandb.login(key='5fb0ebab7b6270cea7a65334f3a35dd47418d31a')
+
 run = wandb.init(
     config=run_config,
     save_code=True)
diff --git a/esc-50/utils.py b/esc-50/utils.py
index d0f5233..a01b2dc 100644
--- a/esc-50/utils.py
+++ b/esc-50/utils.py
@@ -1,26 +1,27 @@
 from fastai.vision.all import *
 from fastaudio.core.all import *
-
 import wandb
 from fastai.callback.wandb import *
 
 
-path = untar_data(URLs.ESC50)
+# path = untar_data(URLs.DOGS)
+path = '/home/lalex/Munka/PycharmProjects2/BME/Thesis/fastaudio-experiments/esc-50/data/dogscats'
+
 
-def get_data(sample_rate=16000, 
-             item_tfms=None, 
-             batch_tfms=None, 
+def get_data(sample_rate=16000,
+             item_tfms=None,
+             batch_tfms=None,
              fold=1,
              batch_size=32,
              path=path,
              seed=1):
     set_seed(seed, True)
-    df = pd.read_csv(path/'meta'/'esc50.csv')
+    df = pd.read_csv(path + '/meta/esc50.csv')
     splitter = IndexSplitter(df[df.fold == fold].index)
     audio_block = AudioBlock(sample_rate=sample_rate)
     data_block = DataBlock(
         blocks=(audio_block, CategoryBlock),
-        get_x=ColReader('filename', pref=path/'audio'),
+        get_x=ColReader('filename', pref=path + '/audio'),
         get_y=ColReader('category'),
         splitter=splitter,
         item_tfms=item_tfms,
@@ -28,12 +29,13 @@ def get_data(sample_rate=16000,
     data = data_block.dataloaders(df, bs=batch_size)
     return data
 
+
 def get_learner(data, arch, n_channels=1, pretrained=True, normalize=True):
     return cnn_learner(data, arch,
                        config=cnn_config(n_in=n_channels),
                        pretrained=pretrained,
                        normalize=normalize,
-                       loss_fn=CrossEntropyLossFlat, 
+                       loss_fn=CrossEntropyLossFlat,
                        metrics=accuracy).to_fp16()
 
 
@@ -41,18 +43,21 @@ def get_learner(data, arch, n_channels=1, pretrained=True, normalize=True):
 # https://enzokro.dev/spectrogram_normalizations/2020/09/10/Normalizing-spectrograms-for-deep-learning.html
 class SpecNormalize(Normalize):
     "Normalize/denorm batch of `TensorImage`"
-    def encodes(self, x:TensorImageBase): return (x-self.mean) / self.std
-    def decodes(self, x:TensorImageBase):
-        f = to_cpu if x.device.type=='cpu' else noop
-        return (x*f(self.std) + f(self.mean))
-    
+
+    def encodes(self, x: TensorImageBase): return (x - self.mean) / self.std
+
+    def decodes(self, x: TensorImageBase):
+        f = to_cpu if x.device.type == 'cpu' else noop
+        return (x * f(self.std) + f(self.mean))
+
+
 class StatsRecorder:
-    def __init__(self, red_dims=(0,2,3)):
+    def __init__(self, red_dims=(0, 2, 3)):
         """Accumulates normalization statistics across mini-batches.
         ref: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.html
         """
-        self.red_dims = red_dims # which mini-batch dimensions to average over
-        self.nobservations = 0   # running number of observations
+        self.red_dims = red_dims  # which mini-batch dimensions to average over
+        self.nobservations = 0  # running number of observations
 
     def update(self, data):
         """
@@ -61,27 +66,27 @@ class StatsRecorder:
         # initialize stats and dimensions on first batch
         if self.nobservations == 0:
             self.mean = data.mean(dim=self.red_dims, keepdim=True)
-            self.std  = data.std (dim=self.red_dims,keepdim=True)
+            self.std = data.std(dim=self.red_dims, keepdim=True)
             self.nobservations = data.shape[0]
-            self.ndimensions   = data.shape[1]
+            self.ndimensions = data.shape[1]
         else:
             if data.shape[1] != self.ndimensions:
                 raise ValueError('Data dims do not match previous observations.')
-            
+
             # find mean of new mini batch
             newmean = data.mean(dim=self.red_dims, keepdim=True)
-            newstd  = data.std(dim=self.red_dims, keepdim=True)
-            
+            newstd = data.std(dim=self.red_dims, keepdim=True)
+
             # update number of observations
             m = self.nobservations * 1.0
             n = data.shape[0]
 
             # update running statistics
             tmp = self.mean
-            self.mean = m/(m+n)*tmp + n/(m+n)*newmean
-            self.std  = m/(m+n)*self.std**2 + n/(m+n)*newstd**2 +\
-                        m*n/(m+n)**2 * (tmp - newmean)**2
-            self.std  = torch.sqrt(self.std)
-                                 
+            self.mean = m / (m + n) * tmp + n / (m + n) * newmean
+            self.std = m / (m + n) * self.std ** 2 + n / (m + n) * newstd ** 2 + \
+                       m * n / (m + n) ** 2 * (tmp - newmean) ** 2
+            self.std = torch.sqrt(self.std)
+
             # update total number of seen samples
             self.nobservations += n
